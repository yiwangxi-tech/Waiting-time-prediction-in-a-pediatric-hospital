{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e536892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from cuml.svm import SVR as cumlSVR\n",
    "from cuml.linear_model import ElasticNet as cuElasticNet\n",
    "from cuml.ensemble import RandomForestRegressor as cuRF\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# ------------------------- Data load and preprocessing -------------------------\n",
    "df = pd.read_excel(\"/home/pumc/tangrui_zy/1F咽拭子-去重-计算A+C.xlsx\")  \n",
    "X = df[[\"Month\", \"Day\", \"Hour\", \"the day of week\", \"the number of queuing patient\", \"Arrival rate\"]].values.astype('float32')\n",
    "y = df[\"Queuing time\"].values.astype('float32')\n",
    "\n",
    "X_cudf = cudf.DataFrame.from_records(X)\n",
    "y_cudf = cudf.Series(y)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- LightGBM-GPU --------------------------------\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'root_mean_squared_error',\n",
    "        'device': 'gpu',\n",
    "        'verbosity': -1,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "    }\n",
    "    rmse_list = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        train_data = lgb.Dataset(X[train_idx], label=y[train_idx])\n",
    "        val_data = lgb.Dataset(X[val_idx], label=y[val_idx])\n",
    "        model = lgb.train(params, train_data, valid_sets=[val_data])\n",
    "        y_pred = model.predict(X[val_idx])\n",
    "        rmse_list.append(root_mean_squared_error(y[val_idx], y_pred))\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study_lgb = optuna.create_study(direction='minimize')\n",
    "study_lgb.optimize(objective_lgb, n_trials=50)\n",
    "best_params_lgb = study_lgb.best_params\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(**best_params_lgb, device='gpu')\n",
    "model_lgb.fit(X, y)\n",
    "preds_lgb = model_lgb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- cuML SVR --------------------------------\n",
    "def objective_svr(trial):\n",
    "    C = trial.suggest_float('C', 0.01, 100, log=True)\n",
    "    epsilon = trial.suggest_float('epsilon', 1e-3, 1.0, log=True)\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    rmse_list = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        svr = cumlSVR(C=C, epsilon=epsilon, gamma=gamma)\n",
    "        svr.fit(X_cudf.iloc[train_idx], y_cudf.iloc[train_idx])\n",
    "        preds = svr.predict(X_cudf.iloc[val_idx])\n",
    "        rmse_list.append(root_mean_squared_error(y[val_idx], cp.asnumpy(preds)))\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study_svr = optuna.create_study(direction='minimize')\n",
    "study_svr.optimize(objective_svr, n_trials=50)\n",
    "best_params_svr = study_svr.best_params\n",
    "\n",
    "model_svr = cumlSVR(**best_params_svr)\n",
    "model_svr.fit(X_cudf, y_cudf)\n",
    "preds_svr = cp.asnumpy(model_svr.predict(X_cudf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- cuML ElasticNet ------------------------------\n",
    "def objective_elastic(trial):\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-4, 10.0, log=True)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.0, 1.0)\n",
    "    rmse_list = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train = X_cudf.iloc[train_idx].reset_index(drop=True)\n",
    "        X_val = X_cudf.iloc[val_idx].reset_index(drop=True)\n",
    "        y_train = y_cudf.iloc[train_idx].reset_index(drop=True)\n",
    "        y_val = y_cudf.iloc[val_idx].reset_index(drop=True)\n",
    "        model = cuElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(cp.asnumpy(y_val.values), cp.asnumpy(preds))\n",
    "        rmse_list.append(rmse)\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study_elastic = optuna.create_study(direction=\"minimize\")\n",
    "study_elastic.optimize(objective_elastic, n_trials=50)\n",
    "best_params_elastic = study_elastic.best_params\n",
    "\n",
    "model_elastic = cuElasticNet(alpha=best_params_elastic[\"alpha\"], l1_ratio=best_params_elastic[\"l1_ratio\"])\n",
    "model_elastic.fit(X_cudf, y_cudf)\n",
    "preds_elastic = cp.asnumpy(model_elastic.predict(X_cudf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- XGBoost --------------------------------\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 0.5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "        \"tree_method\": \"hist\",  \n",
    "        \"random_state\": 0\n",
    "    }\n",
    "\n",
    "    rmse_list = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, preds)\n",
    "        rmse_list.append(rmse)\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=50, timeout=600)\n",
    "best_params_xgb = study_xgb.best_params\n",
    "\n",
    "model_xgb = XGBRegressor(**best_params_xgb)\n",
    "model_xgb.fit(X, y)\n",
    "preds_xgb = model_xgb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1de2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- cuML Random Forest ------------------------------\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 10, 40),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0.3, 1.0),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "    }\n",
    "\n",
    "    val_rmse_scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train = X_cudf.iloc[train_idx].reset_index(drop=True)\n",
    "        X_val = X_cudf.iloc[val_idx].reset_index(drop=True)\n",
    "        y_train = y_cudf.iloc[train_idx].reset_index(drop=True)\n",
    "        y_val = y_cudf.iloc[val_idx].reset_index(drop=True)\n",
    "        model = cuRF(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(cp.asnumpy(y_val.values), cp.asnumpy(preds))\n",
    "        val_rmse_scores.append(rmse)\n",
    "    return np.mean(val_rmse_scores)\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"minimize\")\n",
    "study_rf.optimize(objective_rf, n_trials=50)\n",
    "best_params_rf = study_rf.best_params\n",
    "\n",
    "model_rf = cuRF(**best_params_rf)\n",
    "model_rf.fit(X_cudf, y_cudf)\n",
    "preds_rf = cp.asnumpy(model_rf.predict(X_cudf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Decision Tree --------------------------------\n",
    "def objective_dt(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n",
    "        \"max_features\": trial.suggest_float(\"max_features\", 0.3, 1.0)\n",
    "    }\n",
    "\n",
    "    val_rmse_scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = DecisionTreeRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, preds)\n",
    "        val_rmse_scores.append(rmse)\n",
    "    return np.mean(val_rmse_scores)\n",
    "\n",
    "study_dt = optuna.create_study(direction=\"minimize\")\n",
    "study_dt.optimize(objective_dt, n_trials=50)\n",
    "best_params_dt = study_dt.best_params\n",
    "\n",
    "model_dt = DecisionTreeRegressor(**best_params_dt)\n",
    "model_dt.fit(X, y)\n",
    "preds_dt = model_dt.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6a596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- KNeighborsRegressor --------------------------------\n",
    "def objective_knn(trial):\n",
    "    params = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 3, 20),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2)  # 1: Manhattan distance, 2: Euclidean distance\n",
    "    }\n",
    "\n",
    "    val_rmse_scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = KNeighborsRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, preds)\n",
    "        val_rmse_scores.append(rmse)\n",
    "    return np.mean(val_rmse_scores)\n",
    "\n",
    "study_knn = optuna.create_study(direction=\"minimize\")\n",
    "study_knn.optimize(objective_knn, n_trials=50)\n",
    "best_params_knn = study_knn.best_params\n",
    "\n",
    "model_knn = KNeighborsRegressor(**best_params_knn)\n",
    "model_knn.fit(X, y)\n",
    "preds_knn = model_knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78186095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- Bootstrap evaluation --------------------------------\n",
    "def bootstrap_evaluate(y_true, y_pred, n_bootstrap=1000):\n",
    "    mse_list, rmse_list, mae_list, r2_list = [], [], [], []\n",
    "    for _ in range(n_bootstrap):\n",
    "        indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "        y_true_boot = y_true[indices]\n",
    "        y_pred_boot = y_pred[indices]\n",
    "        mse_list.append(mean_squared_error(y_true_boot, y_pred_boot))\n",
    "        rmse_list.append(root_mean_squared_error(y_true_boot, y_pred_boot))\n",
    "        mae_list.append(mean_absolute_error(y_true_boot, y_pred_boot))\n",
    "        r2_list.append(r2_score(y_true_boot, y_pred_boot))\n",
    "    return {\n",
    "        \"MSE\": (np.mean(mse_list), np.std(mse_list)),\n",
    "        \"RMSE\": (np.mean(rmse_list), np.std(rmse_list)),\n",
    "        \"MAE\": (np.mean(mae_list), np.std(mae_list)),\n",
    "        \"R2\": (np.mean(r2_list), np.std(r2_list))\n",
    "    }\n",
    "\n",
    "# Evalution for all models\n",
    "models = {\n",
    "    \"LightGBM\": preds_lgb,\n",
    "    \"SVR\": preds_svr,\n",
    "    \"ElasticNet\": preds_elastic,\n",
    "    \"XGBoost\": preds_xgb,\n",
    "    \"RandomForest\": preds_rf,\n",
    "    \"DecisionTree\": preds_dt,\n",
    "    \"KNeighborsRegressor\": preds_knn\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, preds in models.items():\n",
    "    results[name] = bootstrap_evaluate(y, preds)\n",
    "\n",
    "# Print result\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"{metric}: {mean:.4f} ± {std:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# ----------------------------- Output of the best hyperparameter summary --------------------------------\n",
    "print(\"LightGBM 最优超参数:\", best_params_lgb)\n",
    "print(\"SVR 最优超参数:\", best_params_svr)\n",
    "print(\"ElasticNet 最优超参数:\", best_params_elastic)\n",
    "print(\"XGBoost 最优超参数:\", best_params_xgb)\n",
    "print(\"RandomForest 最优超参数:\", best_params_rf)\n",
    "print(\"DecisionTree 最优超参数:\", best_params_dt)\n",
    "print(\"KNeighborsRegressor 最优超参数:\", best_params_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
